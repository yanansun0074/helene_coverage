{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect articles about hurricane Helene coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use wayback Machine to scrape everything from a news website\n",
    "\n",
    "2. Use UNC access's News Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. News Bank pdf about \"Helene\" coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Selenium to download news article pdfs from news bank\n",
    "\n",
    "keyword: helene\n",
    "\n",
    "date: Sep 2024 (when the first 3 articles about Helene were published) - Oct 2024?\n",
    "\n",
    "Location: USA - North Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Open URL\n",
    "url = \"https://infoweb.newsbank.com/apps/news/results?hide_duplicates=2&offset=0&maxresults=60&sort=YMD_date%3AD&p=AMNEWS&t=country%3AUSA%21USA/state%3ANC%21USA%2B-%2BNorth%2BCarolina&f=advanced&val-base-0=helene&fld-base-0=alltext&bln-base-1=and&val-base-1=Sep%202024%20-%20Oct%202024&fld-base-1=YMD_date\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "# Download pdf\n",
    "try:\n",
    "    # For I pages\n",
    "    for i in range(2):\n",
    "        # Click \"select all\" box\n",
    "        # await driver.find_element(By.CLASS_NAME, 'search-hits__select-all form-checkbox').click()\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"search-hits__select-all.form-checkbox\"))).click()\n",
    "        # Click next\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"pager__item.pager__item--next\"))).click()\n",
    "        time.sleep(1)\n",
    "except Exception as e:\n",
    "    print(f\"Cannot select page {i}\")\n",
    "    print(e)\n",
    "else:\n",
    "    # Click download button\n",
    "    driver.find_element(By.CLASS_NAME, 'actions-bar__button.actions-bar__button--download').click()\n",
    "    time.sleep(1)\n",
    "    # While there is \"Next\" button\n",
    "    while True:\n",
    "        # Click \"Download\" button in pop-up\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"u-button multidoc-download__button\"))).click()\n",
    "        # wait loader to appear and then disappear\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_selected((By.CLASS_NAME, 'multidoc__button-spinner')))\n",
    "        WebDriverWait(driver, 10).until(EC.invisibility_of_element((By.CLASS_NAME, 'multidoc__button-spinner')))\n",
    "        # Click \"Next\"\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"multidocs_pager_nav next\"))).click()\n",
    "        except:\n",
    "            print(\"No Next found\")\n",
    "            break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is security check of robot. Can't pass ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ended up with manually downloading 5000+ articles by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract text from pdf with <a href = 'https://github.com/jsvine/pdfplumber'>pdfplumber</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   FUNC extract_text_from_pdf()\n",
    "#   Input: directory (str) of pdf\n",
    "#   Output: header (list) - article header information\n",
    "#         article (list) - article text\n",
    "def extract_text_from_pdf(dir, headers, articles):\n",
    "    # header, article = [],[]\n",
    "    with pdfplumber.open(dir) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # extract texts on each page and split texts by \"OpenURL Link\"\n",
    "            texts = page.extract_text().split(\"\\nOpenURL Link\\n\")\n",
    "            # there is no \"OpenURL Link\" on that page\n",
    "            if len(texts) == 1:\n",
    "                articles[-1] += texts[0]\n",
    "            else:\n",
    "                headers.append(texts[0])\n",
    "                articles.append(texts[1])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   FUNC: decompose_header\n",
    "#   Input: header (str)\n",
    "#   Output: append titles, dates, newspapers, authors, and word_counts\n",
    "def decompose_header(header):\n",
    "\n",
    "\n",
    "    date_match = re.search(r\"\\b(September|October) \\d{1,2}, \\d{4}\\b\", header)\n",
    "    \n",
    "    date = date_match.group(0) if date_match else \"\"\n",
    "    dates.append(date)\n",
    "    loc = header.find(date)\n",
    "    titles.append(header[:loc].replace(\"\\n\", \"\"))\n",
    "\n",
    "    texts = header[loc:].split('\\n')\n",
    "    newspapers.append(texts[0][len(date)+1:].replace('| ', \"\"))\n",
    "\n",
    "    # Line three\n",
    "    match = re.search(r\"Author: (.*?)Section: \", texts[1])\n",
    "    author = match.group(1) if match else \"\"\n",
    "    if author == \"\":\n",
    "        author = texts[1][8:]\n",
    "    authors.append(author)\n",
    "    match_word = re.search(r\"(\\d+)\\s*Words\", texts[1])\n",
    "    word_count = match_word.group(1) if match_word else \"\"\n",
    "    word_counts.append(word_count)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC: correct_news_name\n",
    "# Input: newspaper name from NewsBank(str) e.g. Watauga Democrat, The (Boone, NC)\n",
    "# Output: newspaper name corrected e.g. The Watauga Democrat\n",
    "def correct_news_name(newspaper):\n",
    "    if \", The\" in newspaper:\n",
    "        loc = newspaper.find(\", The\")\n",
    "        newspaper = newspaper[:loc]\n",
    "    elif \"(\" in newspaper:\n",
    "        loc = newspaper.find('(')\n",
    "        newspaper = newspaper[:loc]\n",
    "\n",
    "    # Get rid of \"The\" at the beginning\n",
    "    pattern = r\"^The\\s\"\n",
    "    newspaper = re.sub(pattern, \"\", newspaper)\n",
    "    \n",
    "    return newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers1, articles1 = [],[]\n",
    "\n",
    "path = 'News_Article__Fayetteville_Observer_The_NC___October_8_2024__p1 1.pdf'\n",
    "with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # extract texts on each page and split texts by \"OpenURL Link\"\n",
    "            texts = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files under news_bank_pdf\n",
    "directory = 'news_bank_pdf'\n",
    "pdf_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".pdf\")]\n",
    "\n",
    "headers, articles = [],[]\n",
    "# Extract articles and headers from pdfs\n",
    "for path in pdf_paths:\n",
    "    extract_text_from_pdf(path, headers, articles)\n",
    "\n",
    "# Save articles and headers to dataframe\n",
    "temp = pd.DataFrame({\"header\":headers,\n",
    "                    \"article\": articles})\n",
    "\n",
    "# temp.to_csv('articles_20241112.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose headers\n",
    "titles, dates, newspapers, authors, word_counts = [],[],[],[],[]\n",
    "temp['header'].apply(lambda x: decompose_header(x))\n",
    "\n",
    "temp['title'] = titles\n",
    "temp['date'] = dates\n",
    "temp['newspaper'] = newspapers\n",
    "temp['author'] = authors\n",
    "temp['word_count'] = word_counts\n",
    "temp['newspaper'] = temp['newspaper'].apply(lambda x: correct_news_name(x))\n",
    "\n",
    "temp.head()\n",
    "\n",
    "# temp.to_csv(\"articles_20241112_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from newspaper layout with Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install <a href='https://github.com/tesseract-ocr/tesseract'>Tesseract</a> through homebrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF pages to images\n",
    "pages = convert_from_path(\"News_Article__Fayetteville_Observer_The_NC___October_8_2024__p1.pdf\")\n",
    "\n",
    "for page in pages:\n",
    "    # Crop or split image into columns if necessary\n",
    "    text = pytesseract.image_to_string(page, config='--psm 6')  # PSM 6 for uniform block detection\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "from layoutparser.models.detectron2 import catalog\n",
    "import copy\n",
    "import os\n",
    "import requests as requests\n",
    "import layoutparser as lp\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def load_model(\n",
    "        config_path: str = 'lp://<dataset_name>/<model_name>/config',\n",
    "):\n",
    "\n",
    "    config_path_split = config_path.split('/')\n",
    "    dataset_name = config_path_split[-3]\n",
    "    model_name = config_path_split[-2]\n",
    "\n",
    "    # get the URLs from the MODEL_CATALOG and the CONFIG_CATALOG \n",
    "    # (global variables .../layoutparser/models/detectron2/catalog.py)\n",
    "    model_url = catalog.MODEL_CATALOG[dataset_name][model_name]\n",
    "    config_url = catalog.CONFIG_CATALOG[dataset_name][model_name]\n",
    "\n",
    "    # override folder destination:\n",
    "    if 'model' not in os.listdir():\n",
    "        os.mkdir('model')\n",
    "\n",
    "    config_file_path, model_file_path = None, None\n",
    "\n",
    "    for url in [model_url, config_url]:\n",
    "        filename = url.split('/')[-1].split('?')[0]\n",
    "        save_to_path = f\"model/\" + filename\n",
    "        if 'config' in filename:\n",
    "            config_file_path = copy.deepcopy(save_to_path)\n",
    "        if 'model_final' in filename:\n",
    "            model_file_path = copy.deepcopy(save_to_path)\n",
    "\n",
    "        # skip if file exist in path\n",
    "        if filename in os.listdir(\"model\"):\n",
    "            continue\n",
    "        # Download file from URL\n",
    "        r = requests.get(url, stream=True, headers={'user-agent': 'Wget/1.16 (linux-gnu)'})\n",
    "\n",
    "        with open(save_to_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=4096):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "    # load the label map\n",
    "    label_map = catalog.LABEL_MAP_CATALOG[dataset_name]\n",
    "\n",
    "    return lp.models.Detectron2LayoutModel(\n",
    "        config_path=config_file_path,\n",
    "        model_path=model_file_path,\n",
    "        label_map=label_map\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image of the PDF page (or convert PDF to image as above)\n",
    "# image = Image.open(\"page_image.png\")\n",
    "pages = convert_from_path(\"News_Article__Fayetteville_Observer_The_NC___October_8_2024__p1.pdf\")\n",
    "\n",
    "# Error occurs: having trouble finding the model\n",
    "# layout = lp.models.Detectron2LayoutModel(\"lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config\")\n",
    "# layout = lp.models.Detectron2LayoutModel(\"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config\")\n",
    "# layout = lp.Detectron2LayoutModel(\n",
    "# \"./config.yaml\",\n",
    "# \"./model_final.pth\",\n",
    "# extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "# label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "# )\n",
    "\n",
    "# This works\n",
    "# layout = load_model('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config')\n",
    "\n",
    "\n",
    "detected_layout = layout.detect(pages[0])\n",
    "\n",
    "for block in detected_layout:\n",
    "    segment = block.extract(pages)\n",
    "    text = pytesseract.image_to_string(segment)  # OCR on each segment\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Texts from New Readable PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from newspaper layout with LayoutParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \"helen_articles_readable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlotte Observer, The (NC) - October 2, 2024 - page 2\n",
      "October 2, 2024 | Charlotte Observer, The (NC) | Charlotte, North Carolina | Page 2\n",
      "2A THEC HARLOTOTEB SERVER WEDNESDOACYT OBE2R 2 024\n",
      "1't\n",
      "YOUR 7-DAY FORECAST AccuWeather Getn otificationso f nearbyl ightning! YOUR ACTIVITIES FORECAST\n",
      "Get the AccuWeather App\n",
      "Today Tonight Thursday Friday Saturday Sunday Monday Tuesday TodayT hu. Fri. Sat. Sun. Mon. Tue.\n",
      ". \" \\ .I' .,. - ' '\\,~iJ, ' . \" \\.1-(, - FISHINGIN DEX\n",
      "' ' Q ' '\n",
      "~--P\n",
      "~ ~, ' ~\n",
      ")',,,,\n",
      "OUTDOOARC TIVITIEINS DEX\n",
      "Mostlys unny Mainlyc lear, Somes unw ith Humidw ith a Partlys unny Partlys unny Partlys unny Plentyo f sun\n",
      "9\n",
      "andh umid warma ndh umid a showerh; umid briefs hower\n",
      "HIKINGIN DEX\n",
      "or two\n",
      "g30\n",
      "67° 80° 66° 80° 65° 83° 63° 80° 61° 77° 52° 71° 50°\n",
      "-~\n",
      "RealFee8l9, ' ReaFl eel6, 8' RealFee8lS \" RealFee8l2, ' RealFee8l5 ' Realfee8l, 3' Realfee7l 9' Realfee7l 3' GOLFINIGN DEX\n",
      "UVl nde\" 5 UVl nde\" 3 UVl nde\" 2 UVl nde\" 5 UVl nde\" 5 UVl nde\" 5 UVl nde\" 5 6 ...-=--\n",
      "The patented AccuWeather.comR ealfeel Temperature~ is the only index that includesa ll the weather factors that play a role in how we perceivet emperature, including the effects of wind, humidity,\n",
      "sunshine,p redpitation, pressure,a nd elevation. Showna re the highest and lowest valuesf or each day. Theh ighetrh eA ccuWeather.cUoVm In dex\"n' umbetrh, eg reatetrh en eedfo re yea nds kinp rotection. 0-2: Poor3; •4: Fair5; •6: Good7;- 8: VeryG ood9;· 10: Excellent\n",
      "ALMANAC POLLEN INDEX\n",
      "Charlottoen M onday AS OF 9/30\n",
      "TEMPERATURE Grass; Absent\n",
      "HighLlow 82°/66° Trees: Low\n",
      "Normalh igh[low 79'/58' Weeds: Low\n",
      "Lasty ear highLlow 85'/60' Mold: Hig!J.\n",
      "Recordh igh 91' 12019} SourceN: ationaAl llergyB ureau\n",
      "Recordlo w 38' 11888}\n",
      "RIVER LEVELS\n",
      "PRECIPITATION\n",
      "Flood 7 a.m. 24-hour\n",
      "Monday trace\n",
      "Stage(f t.) Tuesday change\n",
      "Montht o date {normal) 9.49• 13.71'1\n",
      "CATAWBAR IVER\n",
      "Yeart o date {normal) 45.54·· (33.68\"}\n",
      "nearP leasanGt ardens 11 2.90 ·0.75 I\n",
      "Lasty eart o date 36.39\" 0\n",
      ".,J 0\n",
      "aboveR ockH ill 15 13.01 -4.92\n",
      "Albemarle Goldsboro\n",
      "COOLING DEGREED AYS Charlotte\n",
      "aboveC atawba 58 19.45 •7 . 21\n",
      "Fayetteville\n",
      "Degredea ysa rea ni ndicatoor f energyn eedsT.h em oreth e 83/67 82/62 80/63\n",
      "tQtadl egredea yst,h em oree nergyis necessatroy C OQL STEWARTC REEK J 83/63 0\n",
      "1/ 0\n",
      "at West MoreheadS treet 14 1.40 +0.07 0\n",
      "Monda 9\n",
      "at State Street 10 1.02 +0.08 1 Pspartanburg RockH ill Monroe Rockingham\n",
      "Montht o date {normal) 277 1247}\n",
      "Greenville \\82/63 ' 83/65 83/63 I\n",
      "82/64\n",
      "Yeart o date {normal) 2023 11708} LITTLE SUGARC REEK\n",
      "Is\n",
      "/OLumberton\n",
      "Lasty eart o date 1760 at MedicaCl enterD rive 13.5 2.17 +0.04 84/67 '\\ Hartsville\n",
      "82/63\n",
      "LaurensO 84/64\n",
      "SUN &MOON\n",
      "LAKE LEVELS\n",
      "0\n",
      "83/64\n",
      "Sunriset oday 7:20 AM Moonriseto day 7,07 AM 0\n",
      "Sunsett onight 7:06 PM Moonsetto day 7,04 PM Normal Ele11ation2 4•hour 0 Newberiy orence\n",
      "Wilmington0\n",
      "PQO(fIt .) Tuesday change\n",
      "Greenwood 84/65\n",
      "New First Full Last 84/64 84/66\n",
      "LakeW ylie 100 99.40 ·0.34\n",
      "/63\n",
      "SumterO\n",
      "LakeN orman 100 99.09 -0.62 -\n",
      "Hlgh RockL ake 655 N.A. N.A. ~ ii~ , 85/66 Myrtle Beach\n",
      "Q\n",
      "\\\n",
      "81/67 O\n",
      "Oct1 Oct10 Oct17 Oct14 Forecasatsn dg raphicpsr ovidedby AccuWeatheInrc, .© 2024\n",
      "TODAY'S NATIONAL FORECAST AROUND THE NATION AROUND THE WORLD\n",
      "Showna ren oonp ositionosf weathesr ystemasn dp recipitatioTn.e mperatubrea ndas reh ighsfo r the day. Today Thursday Today Thursday\n",
      "City Hi LO W Hi LO W City Hi LO W Hi LO W\n",
      "Anchorage 48 38 s 47 39 Acapulco 85 77 t 83 76 t\n",
      "C\n",
      "Atlanta 84 68 s 84 68 s Amsterdam 58 46 sh 59 42 pc\n",
      "Boston 64 55 68 57 pc Baghdad 96 77 pc 94 70 pc\n",
      "C\n",
      "Chicago 73 53 s 80 58 pc Berlin 55 47 sh 56 45 sh\n",
      "Dallas 90 69 s 94 69 s Bogota 67 45 sh 68 46 sh\n",
      "Denver 91 53 s 79 48 s Cairo 86 72 s 85 70 s\n",
      "Detroit 67 47 pc 74 54 pc Calg~a_r_~_y ~5~2-~3~2~ c __ ~5~2-~3~4~p~c_\n",
      "ew York Honolulu 89 75 s 89 74 r Dublin 59 45 sh 58 49 pc\n",
      "'f!bO Indianapolis 70 48 s 78 55 pc Geneva 64 4 7 pc 59 48 sh\n",
      "ington KansasC ity 79 57 pc 88 57 s Havana 90 75 t 87 75 sh\n",
      "LasV egas 103 74 s 103 74 s HongK ong 87 72 s 86 71 pc\n",
      "LosA ngeles 91 67 s 89 64 s Jerusalem 78 59 s 81 61 s\n",
      "Miami 93 79 s 92 80 t Johannesburg 71 42 s 72 43 s\n",
      "Nashville 77 57 pc 83 61 s Lisbon 76 67 c 76 63 c\n",
      "NewO rleans 88 72 s 86 73 sh London 62 48 sh 63 46 pc\n",
      "NewY orkC ity 69 60 C 74 60 pc Madrid 79 61 c 79 54 pc\n",
      "Orlando 86 74 t 88 76 t MexicoC ity 65 51 c 71 54 pc\n",
      "Philadelphia 70 60 C 76 59 pc Moscow 69 44 pc 69 50 pc\n",
      "Phoenix 108 81 s 109 79 s NewD elhi 100 78 s 99 74 s\n",
      "St. Louis 74 53 s 83 58 s Paris 63 51 sh 58 44 c\n",
      "Salt LakeC ity 85 56 s 82 59 s Rome 76 66 c 70 58 sh\n",
      "SanF rancisco 88 59 s 83 57 s Stockholm 51 36 c 52 34 s\n",
      "T-storms Rain Showers Snow Flurries Ice ColdF ront WarmF ront StationarFyr ont Seattle 63 45 pc 65 48 pc Sydney 67 58 sh 68 51 s\n",
      "l,',11:a:4f'''J[:;;*::,l~:•,llvvvvl WashingtonD, C 73 63 pc 78 61 pc Tokyo 86 71 pc 76 71 t\n",
      "¥ ¥ ¥ ♦ ♦ ♦ ,e ¥ •\n",
      "I ·10s 11 ·Os 11 Os 11 lDs 11 20s 11 30s 11 40s I I sos 11 60s I I 70s I I 80s I I 90s I I 100sI l 110sI Weather(Ws)-:s unnyp,c -partlcyl oudyc,- cloudys,h ·showerts-t,h understormr-sr,a ins, f-snowflu rriess, n-snowi-,i ce\n",
      "Western North Carolina\n",
      "members can't reach their\n",
      "loved ones in communities\n",
      "devastated by the storm.\n",
      "communities hope for Families wondered: Are\n",
      "they alive?\n",
      "Karen Morris worried\n",
      "about a relative in the\n",
      "'some sort of lifeline'\n",
      "county who needed to be\n",
      "cared for at home. She got\n",
      "a text Sunday morning:\n",
      "after Helene damage\n",
      "that relative had no pow\n",
      "er, no water and her oxy\n",
      "gen was no longer work\n",
      "mg.\n",
      "\"We tried to get (family)\n",
      "need it. The federal gov in the ravine below. TRAVLISO NG tlong@newsobserver.c toom g et ahold of 911,\" Mor\n",
      "BY RYANO EHRLI ernment also says it will '(But you know: What Swannanoa residents walk through devastating flood ris said. \"We don't know\n",
      "roehrli@charlotteobserver.com reimburse local govern else can you do?\" he damage from the Swannanoa River on Sunday, Sept. 29, yet whether they were\n",
      "ments, state agencies and asked. 2024. The remnants of Hurricane Helene caused able to do that.\"\n",
      "nonprofits for repairs. More help wasn't com widespread flooding. downed trees. and power outages Gov. Roy Cooper said\n",
      "SWANNANOA\n",
      "A long stretch of Rescue workers will ing, he was certain. in western North Carolina. during an interview on\n",
      "Swannanoa is no more. navigate their way ((Where is FEMA at CNN Sunday that families\n",
      "Businesses and homes through a maze of impas when we need it?\" Angela who can't reach their\n",
      "along the Swannanoa sible roads and debris McGee asked as she and workshops for people Black Mountain. The gro loved ones can contact\n",
      "River were destroyed by caused by Helene. Roads walked along that road who want to do unscripted cery store's lot was filled. North Carolina's 211 serv\n",
      "Helene, which hit Florida became rivers. Lakes filled while searching for her theater. Atlantic Beach Fire ice to ask for a welfare\n",
      "as a Category 4 hurricane with debris. And in many mobile home that wound The question for him as Department Deputy Chief check. The United Way,\n",
      "before it dumped historic communities, there,s just up far from its usual spot. he stood by his destroyed Casey Arthur was \"clear which operated the serv\n",
      "rain totals in western nothing left. McGee said she heard hopes: what's next? ing\" a van that had fallen ice, also has a form on its\n",
      "North Carolina as a trop The situation is dire. about a mandatory evac \"Maybe the hard part is into the river with some website to request one.\n",
      "ical storm. At least 30 Many of North Carolina uation late, and she's hoping that there's some National Guardsmen in\n",
      "people have died in Bun communities haven't had currently living with her sort of lifeline and won Swannanoa early Sunday Ryan Oehrli: @oehrli\n",
      "combe County alone, fresh water, internet or kids in her car. dering if that's there, but afternoon, \"making sure\n",
      "Sheriff Quentin Miller cell service for multiple \"We are down here in a then kind of being faced nothing's inside.\"\n",
      "announced in an after days. disaster and no one is with the reality that: No, They'd finish that job\n",
      "noon press briefing. \"It seems like there helping us out,\" she said. there is not,\" he said. and keep moving down CORRECTIAONNDS\n",
      "People in Swannanoa, a would be more people She wants more than a \"Might as well just f-ing the river, he said. Searches\n",
      "CLARIFICATIONS\n",
      "community east of Ashe here by now,\" said Dustin federal agency to show up. laugh about it. Because, started to taper off as\n",
      "ville along Interstate 40, Ebert, whose home is She needs water, cell serv you know, what else is cellphone service returned\n",
      "scrambled for water, gas about 200 yards away ice, shelters and food. there? I already cried.\" in spurts in comers of the See an error or another\n",
      "and other basic supplies from the main stretch of Everything she's learned county. problem with content in\n",
      "this weekend. Help began road that got destroyed in has been through word of NC NATIONALG UARD ((These guys in Swanna this edition? Report it by\n",
      "arriving this weekend Swannanoa. mouth, and she's ((in National Guard hum noa have been running going to\n",
      "from the National Guard His floors got flooded, furiated,\" she said. vees rolled through Black constantly,\" he said. charlotteobserver.com\n",
      "and others traveling from and he has three kids in For about a year Shem Mountain and Swannanoa / customer-serviceo r by\n",
      "across the region. the house. Around him, suddin Millard prepped to on Sunday. Helicopters WESTERNN C CELL calling 1-888-905-2036. To\n",
      "Meanwhile, North Car the roads were covered in open Black Mountain buzzed by every so often. PHONE SERVICE report delivery or account\n",
      "olina received a major dirt and dark mud. Old Improvisational Theater A slew of law enforcement Not being able to call issues, call 800-532-5350.\n",
      "disaster declaration for 25 U.S. Highway 70 was next door to Swannanoa. agencies and the National others has been among\n",
      "counties that will provide fragmented and broken In another two months, he Guard handed out water the biggest problems for\n",
      "quicker help to those who apart, much of it landing could've started lessons bottles at an Ingles in survivors. Panicked family\n",
      "m:~<c! t~arlo®ttbc scrucr TheC harlotteO bservewr eeklys ub· Fory ourc onveniencyeo,u r subscriptionw illa utomaticallrye new TheC harlottOe bserveUr,S P1S0 0-760\n",
      "®\n",
      "scriplionr ates:R atessu bjectto change aftert he initialt erma t the currenrt ateu nlesyso ut ell ust o cancel. is publishewd eeklyW, ednesdaFyr,id ay\n",
      "withoutn oticeA. ll Observesru bscriptions Cancellatiotnask ee ffecta t the endo f yourc urrenst ubscriptiotne rm. andS undayb,y McClatchCyo 2, 459\n",
      "includep rintedn ewspapeprlu su nlimited Alls ubscriptioanc counpt aymentasr en on·refundabalen di nclude WilkinsoBnl vd.S, uite3 10C, harlotteN, C\n",
      "CustomeSr ervice8: 00·532·5350, onlinem, obilea nde ditiona ccess. applicabltea x.O urc ontenits deliveretdo youb yv ariousm ethods 28208(b ya ppointmenotn ly).P eriod\n",
      "charlotteobserver.com/myaccount andf ormatsW. er eservteh er ightt o substitutteh ed eliverya nd icalsp ostagpea ida t CharlotteN, Ca nd\n",
      "Wed.F, ri.,S un. $34.99/week•\n",
      "formato f yourp rints ubscriptiowni tha n Editiona t anyt ime.N otice addltionaml ailingo ffices.\n",
      "Placea ClassifieAd d: 704-358-50o0r0 o nlinea t Sunday $34.99/week•\n",
      "of ratec hangewsi ll be mailedo r emailedto thes ubscribebri lling/\n",
      "PostmasteSr:e nda ll UAAto CFS:\n",
      "classifieds.charlotte.com Wed./5un. $34.99/week•\n",
      "emaial ddresast leas3t 0d aysin advancoef the changeA. $0.59\n",
      "NON-POST&A ML ILITARFYA CILITIES\n",
      "Storyo r photoi dea7 04·358·104800,0 ·283-6459, Single-coprya tes:W ednesdaany dF riday\n",
      "SupplyC hainc hargew illb e appliedw eeklyF. ors ubscribetrhsa t\n",
      "senda ddrescso rrectiontso McClatchy\n",
      "Mon.-Fr9i.: a .m.-6p .m.S; at.-Sunn.o: on-6p .m. $J•/5unda$yS .99\"/5pecEiadli tion$s/ _99•\n",
      "receivae mailedr enewabli ll,a $4.99p rintedb ill feew ill applyf or\n",
      "1601A lhambrBa lvdS uite1 00S acra\n",
      "SustainabilityT:h isn ewspapeisr p rintedin parto n Digitalo nly subscriptions$:3 4.99/week• eachr enewapl eriodA. ll homed eliverys ubscriptionwsil l include\n",
      "mentoC, A9 5816.\n",
      "recyclepda pera ndi s recyclable. deliveryo f theT hanksgivinHgo lidayE ditionA. na dditiona$l 4.99fe e\n",
      "*plusa pplicablsea lesla x\n",
      "will bea ddedto all subscriptionfosr eacho f thesep remiume ditions\n",
      "in 2024fo r 10/13.11/a2n7d 1 2/15a,n di n 2025fo r 4/136, /228, /241, 0/19.\n",
      "11/27Y.o uc anc anceal t anyt imeb yc ontactinCg ustomeSre rvicaet\n",
      "1-800·532·53Y5o0u.r s ubscriptioisn s ubjectto additionaTl ermos f\n",
      "Servicaet https://www.charlotteobserver.com/terms·of·service/.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "path = 'helene_articles_readable/News_Article__Charlotte_Observer_The_NC___October_2_2024__p2.pdf'\n",
    "with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # extract texts on each page and split texts by \"OpenURL Link\"\n",
    "            texts = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Checkpoint /Users/yanans/.torch/iopath_cache/s/6ewh6g8rqt2ev3a/model_final.pth not found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectron2LayoutModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlp://NewspaperNavigator/faster_rcnn_R_50_FPN_3x/config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPhotograph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIllustration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComics/Cartoon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEditorial Cartoon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHeadline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdvertisement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/layoutparser/models/detectron2/layoutmodel.py:119\u001b[0m, in \u001b[0;36mDetectron2LayoutModel.__init__\u001b[0;34m(self, config_path, model_path, label_map, extra_config, enforce_cpu, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_map \u001b[38;5;241m=\u001b[39m label_map\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/layoutparser/models/detectron2/layoutmodel.py:122\u001b[0m, in \u001b[0;36mDetectron2LayoutModel._create_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mdetectron2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/detectron2/engine/defaults.py:320\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    319\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m DetectionCheckpointer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 320\u001b[0m \u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mResizeShortestEdge(\n\u001b[1;32m    323\u001b[0m     [cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST, cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST], cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMAX_SIZE_TEST\n\u001b[1;32m    324\u001b[0m )\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mFORMAT\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/detectron2/checkpoint/detection_checkpoint.py:62\u001b[0m, in \u001b[0;36mDetectionCheckpointer.load\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     path \u001b[38;5;241m=\u001b[39m parsed_url\u001b[38;5;241m.\u001b[39m_replace(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgeturl()  \u001b[38;5;66;03m# remove query from filename\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m---> 62\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_sync:\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcasting model states from main worker ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/fvcore/common/checkpoint.py:153\u001b[0m, in \u001b[0;36mCheckpointer.load\u001b[0;34m(self, path, checkpointables)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[1;32m    152\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path)\n\u001b[1;32m    155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_file(path)\n\u001b[1;32m    156\u001b[0m incompatible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(checkpoint)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Checkpoint /Users/yanans/.torch/iopath_cache/s/6ewh6g8rqt2ev3a/model_final.pth not found!"
     ]
    }
   ],
   "source": [
    "model = lp.models.Detectron2LayoutModel(\n",
    "    config_path=\"lp://NewspaperNavigator/faster_rcnn_R_50_FPN_3x/config\",\n",
    "    label_map={0: \"Photograph\", 1: \"Illustration\", 2: \"Map\", 3: \"Comics/Cartoon\", 4: \"Editorial Cartoon\", 5: \"Headline\", 6: \"Advertisement\"}\n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Checkpoint /Users/yanans/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth not found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load a pre-trained layout detection model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model = lp.models.Detectron2LayoutModel(\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     config_path=\"lp://NewspaperNavigator/faster_rcnn_R_50_FPN_3x/config\",\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     label_map={0: \"Photograph\", 1: \"Illustration\", 2: \"Map\", 3: \"Comics/Cartoon\", 4: \"Editorial Cartoon\", 5: \"Headline\", 6: \"Advertisement\"}\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectron2LayoutModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlp://PubLayNet/faster_rcnn_R_50_FPN_3x/config\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# In model catalog\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mList\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFigure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# In model`label_map`\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMODEL.ROI_HEADS.SCORE_THRESH_TEST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Convert PDF page to image\u001b[39;00m\n\u001b[1;32m     19\u001b[0m pages \u001b[38;5;241m=\u001b[39m convert_from_path(path)\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/layoutparser/models/detectron2/layoutmodel.py:119\u001b[0m, in \u001b[0;36mDetectron2LayoutModel.__init__\u001b[0;34m(self, config_path, model_path, label_map, extra_config, enforce_cpu, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_map \u001b[38;5;241m=\u001b[39m label_map\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/layoutparser/models/detectron2/layoutmodel.py:122\u001b[0m, in \u001b[0;36mDetectron2LayoutModel._create_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mdetectron2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/detectron2/engine/defaults.py:320\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    319\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m DetectionCheckpointer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 320\u001b[0m \u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mResizeShortestEdge(\n\u001b[1;32m    323\u001b[0m     [cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST, cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST], cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMAX_SIZE_TEST\n\u001b[1;32m    324\u001b[0m )\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mFORMAT\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/detectron2/checkpoint/detection_checkpoint.py:62\u001b[0m, in \u001b[0;36mDetectionCheckpointer.load\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     path \u001b[38;5;241m=\u001b[39m parsed_url\u001b[38;5;241m.\u001b[39m_replace(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgeturl()  \u001b[38;5;66;03m# remove query from filename\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m---> 62\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_sync:\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcasting model states from main worker ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/fvcore/common/checkpoint.py:153\u001b[0m, in \u001b[0;36mCheckpointer.load\u001b[0;34m(self, path, checkpointables)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[1;32m    152\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path)\n\u001b[1;32m    155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_file(path)\n\u001b[1;32m    156\u001b[0m incompatible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(checkpoint)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Checkpoint /Users/yanans/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth not found!"
     ]
    }
   ],
   "source": [
    "import layoutparser as lp\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load a pre-trained layout detection model\n",
    "# model = lp.models.Detectron2LayoutModel(\n",
    "#     config_path=\"lp://NewspaperNavigator/faster_rcnn_R_50_FPN_3x/config\",\n",
    "#     label_map={0: \"Photograph\", 1: \"Illustration\", 2: \"Map\", 3: \"Comics/Cartoon\", 4: \"Editorial Cartoon\", 5: \"Headline\", 6: \"Advertisement\"}\n",
    "# )\n",
    "\n",
    "model = lp.Detectron2LayoutModel(\n",
    "            config_path ='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config', # In model catalog\n",
    "            label_map   ={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"}, # In model`label_map`\n",
    "            extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8] # Optional\n",
    ")\n",
    "\n",
    "# Convert PDF page to image\n",
    "pages = convert_from_path(path)\n",
    "page_image = pages[0]  # Example: Process the first page\n",
    "\n",
    "# Detect layout elements\n",
    "layout = model.detect(page_image)\n",
    "\n",
    "# Visualize layout detection (optional)\n",
    "lp.draw_box(page_image, layout, box_width=3, box_color=\"red\").save(\"layout_detected.png\")\n",
    "\n",
    "# Perform OCR on each detected text block\n",
    "for block in layout:\n",
    "    if block.type == \"Text\":  # Check if block is a text region\n",
    "        # Crop text region\n",
    "        cropped_image = page_image.crop(block.coordinates)\n",
    "        \n",
    "        # Apply OCR\n",
    "        text = pytesseract.image_to_string(cropped_image)\n",
    "        print(f\"Text in Block {block.id}:\")\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package detectron2:\n",
      "\n",
      "NAME\n",
      "    detectron2 - # Copyright (c) Facebook, Inc. and its affiliates.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _C\n",
      "    checkpoint (package)\n",
      "    config (package)\n",
      "    data (package)\n",
      "    engine (package)\n",
      "    evaluation (package)\n",
      "    export (package)\n",
      "    layers (package)\n",
      "    model_zoo (package)\n",
      "    modeling (package)\n",
      "    projects (package)\n",
      "    solver (package)\n",
      "    structures (package)\n",
      "    tracking (package)\n",
      "    utils (package)\n",
      "\n",
      "VERSION\n",
      "    0.6\n",
      "\n",
      "FILE\n",
      "    /Users/yanans/Desktop/helene_coverage/.venv/lib/python3.12/site-packages/detectron2/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(\"detectron2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Extract Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import to <a href=\"https://notebooklm.google/\">NotebookLM</a>, an AI document assistant by Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images of Destruction - and Hope\\nOctober 6, 2...</td>\n",
       "      <td>Hurricane Helene swept across the Southeast, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free legal assistance available for Helene sto...</td>\n",
       "      <td>As thousands of North Carolinians continue to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No power but only minor damage: Spruce Pine qu...</td>\n",
       "      <td>The world's main producer of high-purity quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milton takes turn to target Florida on 'destru...</td>\n",
       "      <td>Orlando Sentinel/Tribune Content Agency \\nORLA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Images of Destruction - and Hope\\nOctober 6, 2...   \n",
       "1  They were in the basement frantically preparin...   \n",
       "2  Free legal assistance available for Helene sto...   \n",
       "3  No power but only minor damage: Spruce Pine qu...   \n",
       "4  Milton takes turn to target Florida on 'destru...   \n",
       "\n",
       "                                             article  \n",
       "0  Hurricane Helene swept across the Southeast, c...  \n",
       "1  They were in the basement frantically preparin...  \n",
       "2  As thousands of North Carolinians continue to ...  \n",
       "3  The world's main producer of high-purity quart...  \n",
       "4  Orlando Sentinel/Tribune Content Agency \\nORLA...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdfs = pd.read_csv(\"pdfs.csv\")\n",
    "pdfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/fww9r0gd1mg20td4q8v12_lsknvlj7/T/ipykernel_29009/295378105.py:3: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  pdfs[pdfs['header'] ==head]['article'] += for_str\n",
      "/var/folders/cn/fww9r0gd1mg20td4q8v12_lsknvlj7/T/ipykernel_29009/295378105.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pdfs[pdfs['header'] ==head]['article'] += for_str\n"
     ]
    }
   ],
   "source": [
    "for_str = \"\"\"Dane Jackson won't offer up any spoilers on his status for Sunday's game against the Atlanta Falcons.\\nThe veteran cornerback, who has been on injured reserve since the season started, could make his Carolina Panthers debut this weekend. But for now, he's just doing what he's told, and not sharing those directions with anyone outside of Bank of America Stadium.\\n\"I'm just following the plan that they've got for me,\" Jackson said with a big smile on Thursday after practice.\\nJackson signed a two-year deal with the team in free agency in March. He was projected to be the favorite at the No. 2 cornerback spot opposite Jaycee Horn, but he suffered a notable hamstring injury in training camp in August.\\nAnd he has been sidelined ever since.\\n\"It's been a process, for sure,\" Jackson said. \"Never had a (hamstring injury) to this extent, so it's definitely been a process. But I've been working with the strength staff, with the training room staff - doing my own thing on the side, too - just trying to get to it and get back as healthy as I can.\"\\nJackson built a bond with teammates in trainers room\\nDuring Jackson's stint on the sideline, he bonded with fellow veterans D.J. Wonnum and Amare Barno, who have been on the physically unable to perform (PUP) list since July.\\nThe trio worked in the trainers room together as they went through their respective rehab assignments. The bond between Wonnum and Jackson, in particular, helped the pair get back on the right track to returning to the field.\\n\"We've definitely (grown) closer since we've both been hurt, we've both been out,\" Jackson said. \"We both like to play around a lot. Getting each other through the day - sometimes, you come in here hurt, and you've got to find it yourself. Just getting each other through the days and bonding with each other and growing together as teammates for sure.\"\\nJackson, who played four seasons with the Buffalo Bills, is eager to play. He signed with Carolina largely due to his relationship and background with GM Dan Morgan.\\nThe GM bet on Jackson, who wants to make the most of his opportunity with his \"\"\"\n",
    "head = \"Panthers CB Dane Jackson preparing to return from IR\\nOctober 13, 2024 | Charlotte Observer, The (NC) | Charlotte, North Carolina | Page 36\\nAuthor: Mike Kaye\"\n",
    "pdfs[pdfs['header'] ==head]['article'] += for_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images of Destruction - and Hope\\nOctober 6, 2...</td>\n",
       "      <td>Hurricane Helene swept across the Southeast, c...</td>\n",
       "      <td>Images of Destruction - and Hope</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>THE CHARLOTTEOBSERVER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>MARTHA QUILLIN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free legal assistance available for Helene sto...</td>\n",
       "      <td>As thousands of North Carolinians continue to ...</td>\n",
       "      <td>Free legal assistance available for Helene sto...</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>CHYNA BLACKMON cblackmon@charlotteobserver.com</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No power but only minor damage: Spruce Pine qu...</td>\n",
       "      <td>The world's main producer of high-purity quart...</td>\n",
       "      <td>No power but only minor damage: Spruce Pine qu...</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>BRIAN GORDON</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milton takes turn to target Florida on 'destru...</td>\n",
       "      <td>Orlando Sentinel/Tribune Content Agency \\nORLA...</td>\n",
       "      <td>Milton takes turn to target Florida on 'destru...</td>\n",
       "      <td>October 9, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>RICHARD TRIBOU</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Images of Destruction - and Hope\\nOctober 6, 2...   \n",
       "1  They were in the basement frantically preparin...   \n",
       "2  Free legal assistance available for Helene sto...   \n",
       "3  No power but only minor damage: Spruce Pine qu...   \n",
       "4  Milton takes turn to target Florida on 'destru...   \n",
       "\n",
       "                                             article  \\\n",
       "0  Hurricane Helene swept across the Southeast, c...   \n",
       "1  They were in the basement frantically preparin...   \n",
       "2  As thousands of North Carolinians continue to ...   \n",
       "3  The world's main producer of high-purity quart...   \n",
       "4  Orlando Sentinel/Tribune Content Agency \\nORLA...   \n",
       "\n",
       "                                               title             date  \\\n",
       "0                   Images of Destruction - and Hope  October 6, 2024   \n",
       "1  They were in the basement frantically preparin...  October 6, 2024   \n",
       "2  Free legal assistance available for Helene sto...  October 6, 2024   \n",
       "3  No power but only minor damage: Spruce Pine qu...  October 6, 2024   \n",
       "4  Milton takes turn to target Florida on 'destru...  October 9, 2024   \n",
       "\n",
       "            newspaper                                          author  \\\n",
       "0  Charlotte Observer                           THE CHARLOTTEOBSERVER   \n",
       "1  Charlotte Observer                                  MARTHA QUILLIN   \n",
       "2  Charlotte Observer  CHYNA BLACKMON cblackmon@charlotteobserver.com   \n",
       "3  Charlotte Observer                                    BRIAN GORDON   \n",
       "4  Charlotte Observer                                  RICHARD TRIBOU   \n",
       "\n",
       "  word_count  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic cleaning\n",
    "import re\n",
    "\n",
    "titles, dates, newspapers, authors, word_counts = [],[],[],[],[]\n",
    "pdfs['header'].apply(lambda x: decompose_header(x))\n",
    "\n",
    "pdfs['title'] = titles\n",
    "pdfs['date'] = dates\n",
    "pdfs['newspaper'] = newspapers\n",
    "pdfs['author'] = authors\n",
    "pdfs['word_count'] = word_counts\n",
    "\n",
    "pdfs['newspaper'] = pdfs['newspaper'].apply(lambda x: correct_news_name(x))\n",
    "\n",
    "# pdfs.to_csv(\"new_pdfs_articles_20241209.csv\", index=False)\n",
    "pdfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter news article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat with other articles\n",
    "temp['newspaper'] = temp['newspaper'].apply(lambda x: correct_news_name(x))\n",
    "temp = temp[temp['word_count'].isna() == False]\n",
    "\n",
    "articles = pd.concat([temp, pdfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/fww9r0gd1mg20td4q8v12_lsknvlj7/T/ipykernel_29009/603044345.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  helene_newspaper['newspaper'] = helene_newspaper.Outlet.apply(lambda x: correct_news_name(x))\n"
     ]
    }
   ],
   "source": [
    "county = pd.read_csv('helene_county_newsrooms/WNC Helene counties.csv')\n",
    "\n",
    "# Clean the county name\n",
    "county['County'] = county['County'].str.replace(' (County)', '')\n",
    "\n",
    "news_census = pd.read_excel('helene_county_newsrooms/NC-News-Census-1.xlsx')\n",
    "\n",
    "# Join two datasets\n",
    "helene_news = pd.merge(county, news_census, how='left')\n",
    "\n",
    "# Filter by 'newspaper' & 'digital' types only\n",
    "helene_news.Type = helene_news.Type.str.lower()\n",
    "helene_newspaper = helene_news[helene_news['Type'].isin(['newspaper','digital'])]\n",
    "\n",
    "# Save it locally\n",
    "# helene_newspaper.to_csv('helene_newspaper.csv', index=False)\n",
    "# helene_newspaper = pd.read_csv('helene_newspaper.csv')\n",
    "\n",
    "# Remove \"The \" at the start of the names\n",
    "helene_newspaper['newspaper'] = helene_newspaper.Outlet.apply(lambda x: correct_news_name(x))\n",
    "\n",
    "# Keep necessary info only\n",
    "h_news = helene_newspaper[['County', 'Outlet','newspaper']]\n",
    "\n",
    "# Merge\n",
    "helene_articles = pd.merge(articles, h_news, how=\"inner\")\n",
    "\n",
    "# Save\n",
    "# helene_articles.to_csv('helene_all_articles.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
