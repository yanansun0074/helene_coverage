{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect articles about hurricane Helene coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use wayback Machine to scrape everything from a news website\n",
    "\n",
    "2. Use <a href = \"https://guides.lib.unc.edu/news-Stories/NC-News\"> NewsBank</a>, a global news database resource providing online archives of media publications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. News Bank pdf about \"Helene\" coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Selenium to download news article pdfs from news bank\n",
    "\n",
    "keyword: \"helene\"\n",
    "\n",
    "date: Sep 23, 2024 (when the first 3 articles about Helene were published) - Oct 23, 2024\n",
    "\n",
    "Location: USA - North Carolina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ended up with manually downloading 5000+ articles in groups, because Newsbank requires identification authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract text from pdf with <a href = 'https://github.com/jsvine/pdfplumber'>pdfplumber</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   FUNC extract_text_from_pdf()\n",
    "#   Input: directory (str) of pdf\n",
    "#   Output: header (list) - article header information\n",
    "#         article (list) - article text\n",
    "def extract_text_from_pdf(dir, headers, articles):\n",
    "    # header, article = [],[]\n",
    "    with pdfplumber.open(dir) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # extract texts on each page and split texts by \"OpenURL Link\"\n",
    "            texts = page.extract_text().split(\"\\nOpenURL Link\\n\")\n",
    "            # there is no \"OpenURL Link\" on that page\n",
    "            if len(texts) == 1:\n",
    "                articles[-1] += texts[0]\n",
    "            else:\n",
    "                headers.append(texts[0])\n",
    "                articles.append(texts[1])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   FUNC: decompose_header\n",
    "#   Input: header (str)\n",
    "#   Output: append titles, dates, newspapers, authors, and word_counts\n",
    "def decompose_header(header):\n",
    "\n",
    "\n",
    "    date_match = re.search(r\"\\b(September|October) \\d{1,2}, \\d{4}\\b\", header)\n",
    "    \n",
    "    date = date_match.group(0) if date_match else \"\"\n",
    "    dates.append(date)\n",
    "    loc = header.find(date)\n",
    "    titles.append(header[:loc].replace(\"\\n\", \"\"))\n",
    "\n",
    "    texts = header[loc:].split('\\n')\n",
    "    newspapers.append(texts[0][len(date)+1:].replace('| ', \"\"))\n",
    "\n",
    "    # Line three\n",
    "    match = re.search(r\"Author: (.*?)Section: \", texts[1])\n",
    "    author = match.group(1) if match else \"\"\n",
    "    if author == \"\":\n",
    "        author = texts[1][8:]\n",
    "    authors.append(author)\n",
    "    match_word = re.search(r\"(\\d+)\\s*Words\", texts[1])\n",
    "    word_count = match_word.group(1) if match_word else \"\"\n",
    "    word_counts.append(word_count)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC: correct_news_name\n",
    "# Input: newspaper name from NewsBank(str) e.g. Watauga Democrat, The (Boone, NC)\n",
    "# Output: newspaper name corrected e.g. The Watauga Democrat\n",
    "def correct_news_name(newspaper):\n",
    "    if \", The\" in newspaper:\n",
    "        loc = newspaper.find(\", The\")\n",
    "        newspaper = newspaper[:loc]\n",
    "    elif \"(\" in newspaper:\n",
    "        loc = newspaper.find('(')\n",
    "        newspaper = newspaper[:loc]\n",
    "\n",
    "    # Get rid of \"The\" at the beginning\n",
    "    pattern = r\"^The\\s\"\n",
    "    newspaper = re.sub(pattern, \"\", newspaper)\n",
    "    \n",
    "    return newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files under news_bank_pdf\n",
    "directory = 'news_bank_pdf'\n",
    "pdf_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".pdf\")]\n",
    "\n",
    "headers, articles = [],[]\n",
    "# Extract articles and headers from pdfs\n",
    "for path in pdf_paths:\n",
    "    extract_text_from_pdf(path, headers, articles)\n",
    "\n",
    "# Save articles and headers to dataframe\n",
    "temp = pd.DataFrame({\"header\":headers,\n",
    "                    \"article\": articles})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose headers\n",
    "titles, dates, newspapers, authors, word_counts = [],[],[],[],[]\n",
    "temp['header'].apply(lambda x: decompose_header(x))\n",
    "\n",
    "temp['title'] = titles\n",
    "temp['date'] = dates\n",
    "temp['newspaper'] = newspapers\n",
    "temp['author'] = authors\n",
    "temp['word_count'] = word_counts\n",
    "temp['newspaper'] = temp['newspaper'].apply(lambda x: correct_news_name(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Texts from New Readable PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Extract Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import to <a href=\"https://notebooklm.google/\">NotebookLM</a>, an AI document assistant by Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images of Destruction - and Hope\\nOctober 6, 2...</td>\n",
       "      <td>Hurricane Helene swept across the Southeast, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free legal assistance available for Helene sto...</td>\n",
       "      <td>As thousands of North Carolinians continue to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No power but only minor damage: Spruce Pine qu...</td>\n",
       "      <td>The world's main producer of high-purity quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milton takes turn to target Florida on 'destru...</td>\n",
       "      <td>Orlando Sentinel/Tribune Content Agency \\nORLA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Images of Destruction - and Hope\\nOctober 6, 2...   \n",
       "1  They were in the basement frantically preparin...   \n",
       "2  Free legal assistance available for Helene sto...   \n",
       "3  No power but only minor damage: Spruce Pine qu...   \n",
       "4  Milton takes turn to target Florida on 'destru...   \n",
       "\n",
       "                                             article  \n",
       "0  Hurricane Helene swept across the Southeast, c...  \n",
       "1  They were in the basement frantically preparin...  \n",
       "2  As thousands of North Carolinians continue to ...  \n",
       "3  The world's main producer of high-purity quart...  \n",
       "4  Orlando Sentinel/Tribune Content Agency \\nORLA...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdfs = pd.read_csv(\"pdfs.csv\")\n",
    "pdfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/fww9r0gd1mg20td4q8v12_lsknvlj7/T/ipykernel_29009/295378105.py:3: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  pdfs[pdfs['header'] ==head]['article'] += for_str\n",
      "/var/folders/cn/fww9r0gd1mg20td4q8v12_lsknvlj7/T/ipykernel_29009/295378105.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pdfs[pdfs['header'] ==head]['article'] += for_str\n"
     ]
    }
   ],
   "source": [
    "for_str = \"\"\"Dane Jackson won't offer up any spoilers on his status for Sunday's game against the Atlanta Falcons.\\nThe veteran cornerback, who has been on injured reserve since the season started, could make his Carolina Panthers debut this weekend. But for now, he's just doing what he's told, and not sharing those directions with anyone outside of Bank of America Stadium.\\n\"I'm just following the plan that they've got for me,\" Jackson said with a big smile on Thursday after practice.\\nJackson signed a two-year deal with the team in free agency in March. He was projected to be the favorite at the No. 2 cornerback spot opposite Jaycee Horn, but he suffered a notable hamstring injury in training camp in August.\\nAnd he has been sidelined ever since.\\n\"It's been a process, for sure,\" Jackson said. \"Never had a (hamstring injury) to this extent, so it's definitely been a process. But I've been working with the strength staff, with the training room staff - doing my own thing on the side, too - just trying to get to it and get back as healthy as I can.\"\\nJackson built a bond with teammates in trainers room\\nDuring Jackson's stint on the sideline, he bonded with fellow veterans D.J. Wonnum and Amare Barno, who have been on the physically unable to perform (PUP) list since July.\\nThe trio worked in the trainers room together as they went through their respective rehab assignments. The bond between Wonnum and Jackson, in particular, helped the pair get back on the right track to returning to the field.\\n\"We've definitely (grown) closer since we've both been hurt, we've both been out,\" Jackson said. \"We both like to play around a lot. Getting each other through the day - sometimes, you come in here hurt, and you've got to find it yourself. Just getting each other through the days and bonding with each other and growing together as teammates for sure.\"\\nJackson, who played four seasons with the Buffalo Bills, is eager to play. He signed with Carolina largely due to his relationship and background with GM Dan Morgan.\\nThe GM bet on Jackson, who wants to make the most of his opportunity with his \"\"\"\n",
    "head = \"Panthers CB Dane Jackson preparing to return from IR\\nOctober 13, 2024 | Charlotte Observer, The (NC) | Charlotte, North Carolina | Page 36\\nAuthor: Mike Kaye\"\n",
    "pdfs[pdfs['header'] ==head]['article'] += for_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images of Destruction - and Hope\\nOctober 6, 2...</td>\n",
       "      <td>Hurricane Helene swept across the Southeast, c...</td>\n",
       "      <td>Images of Destruction - and Hope</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>THE CHARLOTTEOBSERVER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>They were in the basement frantically preparin...</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>MARTHA QUILLIN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free legal assistance available for Helene sto...</td>\n",
       "      <td>As thousands of North Carolinians continue to ...</td>\n",
       "      <td>Free legal assistance available for Helene sto...</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>CHYNA BLACKMON cblackmon@charlotteobserver.com</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No power but only minor damage: Spruce Pine qu...</td>\n",
       "      <td>The world's main producer of high-purity quart...</td>\n",
       "      <td>No power but only minor damage: Spruce Pine qu...</td>\n",
       "      <td>October 6, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>BRIAN GORDON</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milton takes turn to target Florida on 'destru...</td>\n",
       "      <td>Orlando Sentinel/Tribune Content Agency \\nORLA...</td>\n",
       "      <td>Milton takes turn to target Florida on 'destru...</td>\n",
       "      <td>October 9, 2024</td>\n",
       "      <td>Charlotte Observer</td>\n",
       "      <td>RICHARD TRIBOU</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Images of Destruction - and Hope\\nOctober 6, 2...   \n",
       "1  They were in the basement frantically preparin...   \n",
       "2  Free legal assistance available for Helene sto...   \n",
       "3  No power but only minor damage: Spruce Pine qu...   \n",
       "4  Milton takes turn to target Florida on 'destru...   \n",
       "\n",
       "                                             article  \\\n",
       "0  Hurricane Helene swept across the Southeast, c...   \n",
       "1  They were in the basement frantically preparin...   \n",
       "2  As thousands of North Carolinians continue to ...   \n",
       "3  The world's main producer of high-purity quart...   \n",
       "4  Orlando Sentinel/Tribune Content Agency \\nORLA...   \n",
       "\n",
       "                                               title             date  \\\n",
       "0                   Images of Destruction - and Hope  October 6, 2024   \n",
       "1  They were in the basement frantically preparin...  October 6, 2024   \n",
       "2  Free legal assistance available for Helene sto...  October 6, 2024   \n",
       "3  No power but only minor damage: Spruce Pine qu...  October 6, 2024   \n",
       "4  Milton takes turn to target Florida on 'destru...  October 9, 2024   \n",
       "\n",
       "            newspaper                                          author  \\\n",
       "0  Charlotte Observer                           THE CHARLOTTEOBSERVER   \n",
       "1  Charlotte Observer                                  MARTHA QUILLIN   \n",
       "2  Charlotte Observer  CHYNA BLACKMON cblackmon@charlotteobserver.com   \n",
       "3  Charlotte Observer                                    BRIAN GORDON   \n",
       "4  Charlotte Observer                                  RICHARD TRIBOU   \n",
       "\n",
       "  word_count  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic cleaning\n",
    "import re\n",
    "\n",
    "titles, dates, newspapers, authors, word_counts = [],[],[],[],[]\n",
    "pdfs['header'].apply(lambda x: decompose_header(x))\n",
    "\n",
    "pdfs['title'] = titles\n",
    "pdfs['date'] = dates\n",
    "pdfs['newspaper'] = newspapers\n",
    "pdfs['author'] = authors\n",
    "pdfs['word_count'] = word_counts\n",
    "\n",
    "pdfs['newspaper'] = pdfs['newspaper'].apply(lambda x: correct_news_name(x))\n",
    "\n",
    "pdfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter news article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat with other articles\n",
    "temp['newspaper'] = temp['newspaper'].apply(lambda x: correct_news_name(x))\n",
    "temp = temp[temp['word_count'].isna() == False]\n",
    "\n",
    "articles = pd.concat([temp, pdfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/fww9r0gd1mg20td4q8v12_lsknvlj7/T/ipykernel_29009/603044345.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  helene_newspaper['newspaper'] = helene_newspaper.Outlet.apply(lambda x: correct_news_name(x))\n"
     ]
    }
   ],
   "source": [
    "county = pd.read_csv('helene_county_newsrooms/WNC Helene counties.csv')\n",
    "\n",
    "# Clean the county name\n",
    "county['County'] = county['County'].str.replace(' (County)', '')\n",
    "\n",
    "news_census = pd.read_excel('helene_county_newsrooms/NC-News-Census-1.xlsx')\n",
    "\n",
    "# Join two datasets\n",
    "helene_news = pd.merge(county, news_census, how='left')\n",
    "\n",
    "# Filter by 'newspaper' & 'digital' types only\n",
    "helene_news.Type = helene_news.Type.str.lower()\n",
    "helene_newspaper = helene_news[helene_news['Type'].isin(['newspaper','digital'])]\n",
    "\n",
    "# Save it locally\n",
    "# helene_newspaper.to_csv('wnc_newspaper.csv', index=False)\n",
    "\n",
    "# Remove \"The \" at the start of the names\n",
    "helene_newspaper['newspaper'] = helene_newspaper.Outlet.apply(lambda x: correct_news_name(x))\n",
    "\n",
    "# Keep necessary info only\n",
    "h_news = helene_newspaper[['County', 'Outlet','newspaper']]\n",
    "\n",
    "# Merge\n",
    "helene_articles = pd.merge(articles, h_news, how=\"inner\")\n",
    "\n",
    "# Save\n",
    "# helene_articles.to_csv('helene_all_articles.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
